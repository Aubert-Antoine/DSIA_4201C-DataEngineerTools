{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de commencer, parcourer le fichier README.rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requête HTTP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un requête HTTP est une requête basé sur le protocole TCP, elle fait partie de la couche application de la couche OSI. Elle permet d'accéder aux données mise à disposition sur une adresse IP (ou url résolue par un DNS) et un port. \n",
    "\n",
    "Les deux ports les plus utilisé dans le web sont le 80 pour les sites en HTTP et le 443 pour les sites en HTTPS. HTTPS est une variable du protocole HTTP basé sur le protocole TLS.\n",
    "\n",
    "Il existe de nombreux types de requêtes selon la convention `REST`: \n",
    "- GET\n",
    "- POST\n",
    "- PUT \n",
    "- DELETE\n",
    "- UPDATE.\n",
    "\n",
    "Dans notre cas nous allons utiliser la plupart du temps des GET et potentiellement des POST. \n",
    "- Le GET permet comme sont nom l'indique de récupérer des informations en fonction de certain paramètres. \n",
    "- Le POST nécéssite un envoie de données pour récupérer des données. Le body du post est, la plupart du temps, envoyé sous la forme d'un objet JSON.\n",
    "\n",
    "Ces requêtes encapsulent un certain nombre de paramètres qui permettent soient d'identifier une provenance et un utilisateur ou de réaliser différentes actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:28:46.297672500Z",
     "start_time": "2023-11-21T12:28:45.936842900Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Set, Any\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:28:47.646447500Z",
     "start_time": "2023-11-21T12:28:46.297672500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.esiee.fr/\"\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe deux méthodes pour récupérer le contenu de la page :\n",
    "\n",
    "- `response.text` qui permet de retourner le texte sous la forme d'une chaine de charactères.\n",
    "- `response.content` qui permet de récupérer le contenu de la page sous la forme de bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:28:47.668620500Z",
     "start_time": "2023-11-21T12:28:47.646447500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "bytes"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:28:47.669622700Z",
     "start_time": "2023-11-21T12:28:47.653290300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour récupérer les 1000 premiers charactères de la page :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:28:47.802501100Z",
     "start_time": "2023-11-21T12:28:47.668620500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'<!DOCTYPE html>\\n<html lang=\"fr-FR\">\\n<head>\\n\\n<meta charset=\"utf-8\">\\n<!-- \\n\\tThis website is powered by TYPO3 - inspiring people to share!\\n\\tTYPO3 is a free open source Content Management Framework initially created by Kasper Skaarhoj and licensed under GNU/GPL.\\n\\tTYPO3 is copyright 1998-2023 of Kasper Skaarhoj. Extensions are copyright of their respective owners.\\n\\tInformation and contribution at https://typo3.org/\\n-->\\n\\n\\n\\n<title>ESIEE Paris, l&#039;école de l&#039;innovation technologique | ESIEE Paris</title>\\n<meta name=\"generator\" content=\"TYPO3 CMS\" />\\n<meta name=\"description\" content=\"Rejoignez ESIEE Paris, grande école d&#039;ingénieur dans les domaines des transitions numérique, énergétique et environnementale. Classée dans le groupe A, parmi les meilleures écoles d&#039;ingénieur selon le classement de l&#039;Etudiant. Habilitée par la Commission des Titres d&#039;Ingénieur (CTI). Membre de la Conférence des Grandes Ecoles (CGE). \" />\\n<meta name=\"viewport\" content=\"width=device-width'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour récupérer les headers HTTP de la réponse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:28:47.803028700Z",
     "start_time": "2023-11-21T12:28:47.678092800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Date': 'Tue, 21 Nov 2023 12:26:54 GMT', 'Server': 'Apache', 'Content-Language': 'fr', 'Vary': 'Accept-Encoding', 'Content-Encoding': 'gzip', 'X-UA-Compatible': 'IE=edge', 'X-Content-Type-Options': 'nosniff', 'Content-Length': '15693', 'Content-Type': 'text/html; charset=utf-8', 'X-Varnish': '27521 674012', 'Age': '113', 'Via': '1.1 varnish (Varnish/7.1)', 'Accept-Ranges': 'bytes', 'Connection': 'keep-alive'}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut modifier les paramêtres de la requête et/ou ses headers. On peut par exemple ajouter un UserAgent et un timeout de 10 secondes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:28:48.861811Z",
     "start_time": "2023-11-21T12:28:47.686510500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "b'<!DOCTYPE html>\\n<html lang=\"fr-FR\">\\n<head>\\n\\n<meta charset=\"utf-8\">\\n<!-- \\n\\tThis website is powered by TYPO3 - inspiring people to share!\\n\\tTYPO3 is a free open source Content Management Framework initially created by Kasper Skaarhoj and licensed under GNU/GPL.\\n\\tTYPO3 is copyright 1998-2023 of Kasper Skaarhoj. Extensions are copyright of their respective owners.\\n\\tInformation and contribution at https://typo3.org/\\n-->\\n\\n\\n\\n<title>ESIEE Paris, l&#039;\\xc3\\xa9cole de l&#039;innovation technologique | ESIEE Paris</title>\\n<meta name=\"generator\" content=\"TYPO3 CMS\" />\\n<meta name=\"description\" content=\"Rejoignez ESIEE Paris, grande \\xc3\\xa9cole d&#039;ing\\xc3\\xa9nieur dans les domaines des transitions num\\xc3\\xa9rique, \\xc3\\xa9nerg\\xc3\\xa9tique et environnementale. Class\\xc3\\xa9e dans le groupe A, parmi les meilleures \\xc3\\xa9coles d&#039;ing\\xc3\\xa9nieur selon le classement de l&#039;Etudiant. Habilit\\xc3\\xa9e par la Commission des Titres d&#039;Ing\\xc3\\xa9nieur (CTI). Membre de la Conf\\xc3\\xa9rence des Grandes Ecoles (CGE). \" />\\n<meta name=\"viewport\" content=\"width='"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "response = requests.get(url, headers=headers, timeout = 10)\n",
    "response.content[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1\n",
    "\n",
    "- Créer une classe Python permettant de faire des requêtes HTTP.\n",
    "- Cette classe doit utiliser toujours le même UserAgent.\n",
    "- Le TimeOut sera spécifié à chaque appelle avec une valeur par défaut.\n",
    "- Un mécanisme de retry sera mis en place de façon recursive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercice 2\n",
    "\n",
    "- Faire une fonction permettant de supprimer tous les espaces supperflus d'une string\n",
    "- Faire une fonction qui prend une string html et renvois une string intelligible (enlever les caractères spéciaux,\n",
    "- Récupérer le domaine en fonction d'un url"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "import requests, random\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "class RequestHTTP:\n",
    "\t\"\"\"\n",
    "\tCustom class that makes HTTP request\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tdef __init__(self, url, time_out=10):\n",
    "\t\t\t\n",
    "\t\tself.user_agent = self.get_user_agent()\n",
    "\t\tself.time_out = time_out\n",
    "\t\tself.url = url\n",
    "\t\n",
    "\t\n",
    "\tdef get_soup_response(self):\n",
    "\t\t\"\"\"\n",
    "\t\t:return: the http response for the url\n",
    "\t\t\"\"\"\n",
    "\t\ttry:\n",
    "\t\t\tresponse = requests.get(url=self.url, headers= self.user_agent, timeout=self.time_out)\n",
    "\t\texcept requests.Timeout:\n",
    "\t\t\t# Handle timeout exception, you may want to retry or take other actions\n",
    "\t\t\tresponse = requests.get(url=url, headers={'User-Agent': self.user_agent}, timeout=self.time_out * 10)\n",
    "\t\texcept requests.RequestException as e:\n",
    "\t\t\t# Handle other request-related exceptions\n",
    "\t\t\tprint(f\"An error occurred: {e}\")\n",
    "\t\t\tresponse = None\n",
    "\t\t\n",
    "\t\tassert response is not None and response.status_code in [200, 203], \"The status code seems to have a problem\"\n",
    "\t\t\n",
    "\t\treturn BeautifulSoup(response.text)\n",
    "\n",
    "\t\n",
    "\t@staticmethod\n",
    "\tdef remove_spaces_in_row(input_str : str) -> str :\n",
    "\t\tinput_strip = input_str.strip()\n",
    "\t\twhile \"  \" in input_strip :\n",
    "\t\t\tinput_strip = input_strip.replace(\"  \", \" \")\n",
    "\t\treturn input_strip\n",
    "\t\n",
    "\t\n",
    "\t@staticmethod\n",
    "\tdef remove_isnotalnum(input : str)-> str :\n",
    "\t\toutput = str\n",
    "\t\tfor i in input:\n",
    "\t\t\tif i.isalnum() : output += i\n",
    "\t\treturn str(output)\n",
    "\t\t\n",
    "\t\t\n",
    "\tdef get_domain_name(self) -> str:\n",
    "\t\tright_str = self.url.split('.', maxsplit=1)[1]\n",
    "\t\tdomain = right_str.split('/')[0]\n",
    "\t\t\n",
    "\t\treturn domain\n",
    "\t\n",
    "\t@staticmethod\n",
    "\tdef get_user_agent() -> dict:\n",
    "\t\t\"\"\"\n",
    "\t\tRead the user_agent.json file and return randomly one\n",
    "\t\t:return: \n",
    "\t\t\"\"\"\n",
    "\t\twith open('user_agent.json', encoding='utf-8') as agent_list:\n",
    "\t\t\tagent_dict = json.load(agent_list)\n",
    "\t\t\trandom_choise = random.choice(list(agent_dict.keys()))\n",
    "\t\t\treturn {'User-Agent' : agent_dict[random_choise][\"value\"]}\n",
    "\t"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T13:38:17.293840900Z",
     "start_time": "2023-11-21T13:38:17.293840900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url : http://www.esiee.fr/\n",
      "dom : esiee.fr\n",
      "user agent : {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<h2 class=\"h1-like\">ESIEE Paris, <strong>l’école de</strong><br/>\n l'innovation <strong>technologique</strong></h2>,\n <h2 class=\"h1-like\">Venez aux journées <br/><strong>portes ouvertes ESIEE Paris</strong></h2>,\n <h2 class=\"h1-like\">Envie d’en savoir plus sur la réalité de la vie d’un élève en école d’ingénieurs ?</h2>,\n <h2 class=\"sr-only\">Barre de recherche</h2>,\n <h2 class=\"\" id=\"c9-header\">\n                 Nos <strong>formations</strong></h2>,\n <h2 class=\"\" id=\"c7-header\"><strong>Les news</strong> de l'école\n             </h2>,\n <h2><strong>Un cadre unique</strong> où étudier, près de paris</h2>,\n <h2 class=\"\" id=\"c8-header\">\n                 Toutes les <strong>filières</strong></h2>,\n <h2>ESIEE Paris <strong>au coeur de la recherche</strong></h2>,\n <h2 class=\"\" id=\"c43-header\">\n                 Relations <strong>entreprises</strong></h2>,\n <h2>Témoignages</h2>]"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "http_request = RequestHTTP(url=\"http://www.esiee.fr/\")\n",
    "\n",
    "print(\"url : {}\\ndom : {}\\nuser agent : {}\".format(http_request.url, http_request.get_domain_name(), http_request.user_agent))\n",
    "\n",
    "soup = http_request.get_soup_response()\n",
    "\n",
    "soup.find_all(class_=\"h1\")\n",
    "# soup.find_all(\"a\")[0:5]\n",
    "soup.find_all(\"h2\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T13:44:16.162753100Z",
     "start_time": "2023-11-21T13:44:15.532524800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploitation du HTML  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, il faut récupérer le code HTML d'un site web à partir d'une requête. Lorsque vous avez récupéré le texte d'un site il faut le parser. Pour cela, on utilise BeautifulSoup qui permet de transformer la structure HTML en objet Python. Cela permet de récupérer efficacement les données qui nous intéresse.\n",
    "\n",
    "Pour les webmasters, le blocage le plus souvent mis en place et un blocage sur le User-Agent. Le User-Agent est un paramètre intégré dans la requête HTTP réalisé par le Navigateur pour envoyer au front des informations basiques :\n",
    "\n",
    "- la version du Navigateur,\n",
    "- la version de l'OS\n",
    "- Le type de gestionnaire graphique (Gecko)\n",
    "- le type de device utilisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de User Agent :  \n",
    "\n",
    "`Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons à utiliser `BeautifulSoup`, pour l'installer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:29:17.933216600Z",
     "start_time": "2023-11-21T12:28:49.770637500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\antoi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bs4) (4.11.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\antoi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (pyproject.toml): started\n",
      "  Building wheel for bs4 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1266 sha256=cbd87a23f23347efd5186ecd4b7b9981697db331a82cc344edc8674e6a4ad121\n",
      "  Stored in directory: c:\\users\\antoi\\appdata\\local\\pip\\cache\\wheels\\d4\\c8\\5b\\b5be9c20e5e4503d04a6eac8a3cd5c2393505c29f02bea0960\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Requirement already satisfied: lxml in c:\\users\\antoi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.9.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install  lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:29:18.288940700Z",
     "start_time": "2023-11-21T12:29:17.933216600Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour transformer une requête (requests) en objet BeautifulSoup :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:29:19.460990900Z",
     "start_time": "2023-11-21T12:29:18.288940700Z"
    }
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il se peut qu'un message d'erreur arrive à ce point là si vous n'avez pas la librarie `lxml` installée, pour se faire vous avez juste à lancer la commande suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:29:24.961624300Z",
     "start_time": "2023-11-21T12:29:19.465882100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\antoi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.9.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas-1.5.3.dist-info due to invalid metadata entry 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour trouver tous les liens d'une page on récupère la balise `a` qui permet de gérer les liens en HTML  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:29:24.986151100Z",
     "start_time": "2023-11-21T12:29:24.961624300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<a href=\"/#content\">Aller au contenu</a>,\n <a href=\"/#menu\">Aller au menu</a>,\n <a href=\"/plan-du-site/\">Plan du site</a>,\n <a href=\"/nous-rencontrer-1\">Bien choisir son école, c'est aussi la rencontrer  ! Rendez-vous à la prochaine journée portes ouvertes le 9 décembre.</a>,\n <a href=\"/\"><img alt=\"ESIEE PARIS\" class=\"a42-ac-replace-img\" src=\"/typo3conf/ext/esiee_sitepackage/Resources/Public/imgs/svg/logo-esiee.svg\"/></a>,\n <a href=\"/brochures-1\">Brochures</a>,\n <a href=\"/informations/etudiantes-et-etudiants\">Espace élèves</a>,\n <a href=\"/\" hreflang=\"fr-FR\" title=\"Français\">\n <span>Fr</span>\n </a>,\n <a href=\"/en/\" hreflang=\"en-US\" title=\"English\">\n <span>En</span>\n </a>,\n <a href=\"/candidater-1\">Candidater</a>]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"a\")[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut préciser la classe HTML voulue  pour l'ensemble des `a`:\n",
    "\n",
    "```python\n",
    "soup.find_all(class_=\"<CLASS_NAME>\")[0:10]\n",
    "```\n",
    "\n",
    "Ici par exemple: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:29:25.088362100Z",
     "start_time": "2023-11-21T12:29:24.974932200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"slide\")[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour récupérer le text sans les balises HTML :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:29:25.124699600Z",
     "start_time": "2023-11-21T12:29:25.000894400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n\\n\\n\\nESIEE Paris, l'école de l'innovation technologique | ESIEE Paris\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAller au contenu\\nAller au menu\\nPlan du site\\n\\n\\n\\n\\n\\n\\n\\nBien choisir son école, c'est aussi la rencontrer  ! Rendez-vous à la prochaine journée portes ouvertes le 9 décembre.\\n\\n\\n\\n\\n\\nMasquer l'alerte\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBrochuresEspace élèves\\n\\n\\n\\nFr\\n\\n\\n\\n\\nEn\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAfficherMasquer la recherche\\r\\n\\t\\t\\n\\n\\n\\nSaisissez votre recherche\\xa0:\\n\\nLancer la recherche\\n\\n\\n\\nCandidater\\n\\nAfficherMasquer le menu\\n\\n\\n\\n\\n\\nRetour au menu principalAfficherMasquer le sous menu\\xa0: L'écolePourquoi choisir ESIEE Paris ?AfficherMasquer le sous menu\\xa0: Gouvernance et conseilsGouvernance et conseilsConseil scientifiqueAfficherMasquer le sous menu\\xa0: Départements d'enseignements et de rechercheInformatique et télécommunicationsIngénierie des systèmes cyberphysiquesIngénierie industrielleSanté, énergie et environnement durableManagement, sciences humaines et languesCorps professoralAfficherMasquer le sous menu\\xa0: Salles blanchesSalles blanchesÉquipements\""
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "### Exercice 3\n",
    "\n",
    "Améliorer la classe développé précédemment.\n",
    "\n",
    "- Ajouter une méthode pour récupérer l'objet soup d'un url\n",
    "- Récupérer une liste de User Agent et effectuer une rotation aléatoire sur celui à utiliser\n",
    "- Utiliser cette classe pour parser une page HTML et récupérer : le titre, tous les H1 (si ils existent), les liens vers les images, les liens sortants vers d'autres sites, et le texte principal.\n",
    "\n",
    "Parsing d'un sitemaps pour récupérer une listes de liens avec les informations disponibles. -> Stocker dans un dictionnaire et dans un fichier JSON local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploitation des appels d'API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Losque le front du site récupère des données sur une API géré par le back, un appel d'API est réalisé. Cet appel est recensé dans les appels réseaux. Il est alors possible de re-jouer cet appel pour récupérer à nouveau les données. Il est très facile de récupérer ces appels dans l'onglet Network de la console développeur de Chrome ou FireFox. La console vous permet de copier le code CURL pour effectuée et vous pouvez ensuite la transformer en code Python depuis le site https://curl.trillworks.com/.\n",
    "\n",
    "Souvent les APIs sont bloquées avec certain paramètres. L'API verifie que dans les headers de la requêtes HTTP ces paramètres sont présents : * un token généré à la volée avec des protocole OAuth2 (ou moins développés). * un referer provenant du site web (la source de la requête), très facile à falsifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice \n",
    "### Exercice 4\n",
    "\n",
    "- Utiliser les informations développées plus haut pour récupérer les premiers résultats d'une recherche d'une requête\n",
    "sur Qwant. \n",
    "\n",
    "Tips : \n",
    "\n",
    "- Aller sur https://www.qwant.com/\n",
    "- Ouvrir les outils de développements de Chrome ou Firefox\n",
    "- Onglet Network\n",
    "- Fouiller dans les requêtes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice Final  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice Final\n",
    "Utilisez tout ce que vous avez appris pour récupérer des articles de News avec une catégorie. Il est souvent intéressant de partir des flux RSS pour commencer :\n",
    "\n",
    "Les données doivent comprendre :\n",
    "- Le texte important propre\n",
    "- L'url\n",
    "- Le domaine\n",
    "- la catégorie\n",
    "- Le titre de l'article\n",
    "- Le titre de la page\n",
    "- (Facultatif) : les images\n",
    "\n",
    "Tips : \n",
    "\n",
    "- Taper le nom de votre média favoris + RSS (par exemple : https://www.lemonde.fr/rss/)\n",
    "- Aller dans le DOM de la page \n",
    "- Trouver les catégories et les liens vers les articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T12:29:25.125701Z",
     "start_time": "2023-11-21T12:29:25.010504500Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
